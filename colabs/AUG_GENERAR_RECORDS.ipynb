{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AUG_GENERAR_RECORDS.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AY_m2LN9jGqJ",
        "colab_type": "text"
      },
      "source": [
        "## IMAGES & AUGMENTATION\n",
        "\n",
        "Antes de usar este Colab, debemos:\n",
        "\n",
        "Seleccionar las imágenes de plantas. Redimensionarlas a 640x480 y dividirlas en 2 sets\n",
        "(training/test). Etiquetar las imágenes en LabelImg (generando un .xml por cada .jpg) y subirlas a GitHub.\n",
        "\n",
        "\n",
        "Este Colab agarra las imágenes y los .xml desde GitHub y genera archivos .record que son usados para el entrenamiento,\n",
        "los cuales deben ser subidos manualmente (por el momento) a GitHub."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TFnJpXrHcg0E",
        "colab_type": "text"
      },
      "source": [
        "###Clonamos repo que contiene imagenes y xmls"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yxIEIeWnaYYa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "repo_url = 'https://github.com/mapo-lp/obj_det_plantas' #@param {type:\"string\"}\n",
        "\n",
        "import os\n",
        "\n",
        "%cd /content\n",
        "\n",
        "repo_dir_path = os.path.abspath(os.path.join('.', os.path.basename(repo_url)))\n",
        "\n",
        "!git clone {repo_url}\n",
        "%cd {repo_dir_path}\n",
        "\n",
        "!git pull"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RKRF6s9Xer-N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd /content\n",
        "!git clone --quiet https://github.com/tensorflow/models.git\n",
        "\n",
        "!apt-get install -qq protobuf-compiler python-pil python-lxml python-tk\n",
        "\n",
        "!pip install -q Cython contextlib2 pillow lxml matplotlib\n",
        "\n",
        "!pip install -q pycocotools\n",
        "\n",
        "%cd /content/models/research\n",
        "!protoc object_detection/protos/*.proto --python_out=.\n",
        "\n",
        "import os\n",
        "os.environ['PYTHONPATH'] += ':/content/models/research/:/content/models/research/slim/'\n",
        "\n",
        "!python object_detection/builders/model_builder_test.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sOkJ77C4kWwW",
        "colab_type": "text"
      },
      "source": [
        "###Aumentamos imagenes. Generamos 10 imagenes por cada imagen original"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AfEMEUvEcw9y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import imgaug as ia\n",
        "ia.seed(1)\n",
        "# imgaug uses matplotlib backend for displaying images\n",
        "%matplotlib inline\n",
        "from imgaug.augmentables.bbs import BoundingBox, BoundingBoxesOnImage\n",
        "from imgaug import augmenters as iaa \n",
        "# imageio library will be used for image input/output\n",
        "import imageio\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import os\n",
        "import glob\n",
        "# this library is needed to read XML files for converting it into CSV\n",
        "import xml.etree.ElementTree as ET\n",
        "import shutil"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g02Z6rO8czDt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Function that will extract column data for our CSV file as pandas DataFrame\n",
        "def xml_to_csv(path):\n",
        "    xml_list = []\n",
        "    for xml_file in glob.glob(path + '/*.xml'):\n",
        "        tree = ET.parse(xml_file)\n",
        "        root = tree.getroot()\n",
        "        for member in root.findall('object'):\n",
        "            value = (root.find('filename').text,\n",
        "                     int(root.find('size')[0].text),\n",
        "                     int(root.find('size')[1].text),\n",
        "                     member[0].text,\n",
        "                     int(member[4][0].text),\n",
        "                     int(member[4][1].text),\n",
        "                     int(member[4][2].text),\n",
        "                     int(member[4][3].text)\n",
        "                     )\n",
        "            xml_list.append(value)\n",
        "    column_name = ['filename', 'width', 'height', 'class', 'xmin', 'ymin', 'xmax', 'ymax']\n",
        "    xml_df = pd.DataFrame(xml_list, columns=column_name)\n",
        "    return xml_df\n",
        "   \n",
        "# apply the function to convert all XML files in images/ folder into labels.csv\n",
        "if os.path.exists(\"/content/obj_det_plantas/models/object_detection/data/annotations\"):\n",
        "  shutil.rmtree(\"/content/obj_det_plantas/models/object_detection/data/annotations\")\n",
        "\n",
        "os.mkdir('/content/obj_det_plantas/models/object_detection/data/annotations') \n",
        "\n",
        "train_labels_df = xml_to_csv('/content/obj_det_plantas/models/object_detection/data/images/train')\n",
        "train_labels_df.to_csv(('/content/obj_det_plantas/models/object_detection/data/annotations/temp_train_labels.csv'), index=None)\n",
        "\n",
        "test_labels_df = xml_to_csv('/content/obj_det_plantas/models/object_detection/data/images/test')\n",
        "test_labels_df.to_csv(('/content/obj_det_plantas/models/object_detection/data/annotations/temp_test_labels.csv'), index=None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bwHIm9hhc1r7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# function to convert BoundingBoxesOnImage object into DataFrame\n",
        "def bbs_obj_to_df(bbs_object):\n",
        "#     convert BoundingBoxesOnImage object into array\n",
        "    bbs_array = bbs_object.to_xyxy_array()\n",
        "#     convert array into a DataFrame ['xmin', 'ymin', 'xmax', 'ymax'] columns\n",
        "    df_bbs = pd.DataFrame(bbs_array, columns=['xmin', 'ymin', 'xmax', 'ymax'])\n",
        "    return df_bbs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eJiTWsD8c3G8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def resize_imgaug(df, images_path, aug_images_path, image_prefix):\n",
        "    # create data frame which we're going to populate with augmented image info\n",
        "    aug_bbs_xy = pd.DataFrame(columns=\n",
        "                              ['filename','width','height','class', 'xmin', 'ymin', 'xmax', 'ymax']\n",
        "                             )\n",
        "    grouped = df.groupby('filename')    \n",
        "    \n",
        "    for filename in df['filename'].unique():\n",
        "    #   Get separate data frame grouped by file name\n",
        "        group_df = grouped.get_group(filename)\n",
        "        group_df = group_df.reset_index()\n",
        "        group_df = group_df.drop(['index'], axis=1)\n",
        "        \n",
        "        aug_bbs_xy = pd.concat([aug_bbs_xy, group_df])\n",
        "    # return dataframe with updated images and bounding boxes annotations \n",
        "    aug_bbs_xy = aug_bbs_xy.reset_index()\n",
        "    aug_bbs_xy = aug_bbs_xy.drop(['index'], axis=1)\n",
        "    return aug_bbs_xy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XXxxyfGHc5SQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "resized_train_images_df = resize_imgaug(train_labels_df, 'models/object_detection/data/images/train/', 'models/object_detection/data/images/train/', '')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mi0J24Loc63i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "resized_test_images_df = resize_imgaug(test_labels_df, 'models/object_detection/data/images/test/', 'models/object_detection/data/images/test/', '')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HDULYmHic86-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "aug = iaa.SomeOf(2, [    \n",
        "    iaa.Affine(scale=(0.5, 1.5)),\n",
        "    iaa.Affine(rotate=(-60, 60)),\n",
        "    iaa.Affine(translate_percent={\"x\":(-0.3, 0.3),\"y\":(-0.3, 0.3)}),\n",
        "    iaa.Fliplr(1),\n",
        "    iaa.Multiply((0.5, 1.5)),\n",
        "    iaa.GaussianBlur(sigma=(1.0, 3.0)),\n",
        "    iaa.AdditiveGaussianNoise(scale=(0.03*255, 0.05*255))\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iYaHlUfqc-Xn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def image_aug(df, images_path, aug_images_path, image_prefix, augmentor):\n",
        "    # create data frame which we're going to populate with augmented image info\n",
        "    aug_bbs_xy = pd.DataFrame(columns=\n",
        "                              ['filename','width','height','class', 'xmin', 'ymin', 'xmax', 'ymax']\n",
        "                             )\n",
        "    grouped = df.groupby('filename')\n",
        "    \n",
        "    for filename in df['filename'].unique():\n",
        "    #   get separate data frame grouped by file name\n",
        "        group_df = grouped.get_group(filename)\n",
        "        group_df = group_df.reset_index()\n",
        "        group_df = group_df.drop(['index'], axis=1)   \n",
        "    #   read the image\n",
        "        image = imageio.imread(images_path+filename)\n",
        "    #   get bounding boxes coordinates and write into array        \n",
        "        bb_array = group_df.drop(['filename', 'width', 'height', 'class'], axis=1).values\n",
        "    #   pass the array of bounding boxes coordinates to the imgaug library\n",
        "        bbs = BoundingBoxesOnImage.from_xyxy_array(bb_array, shape=image.shape)\n",
        "    #   apply augmentation on image and on the bounding boxes\n",
        "        image_aug, bbs_aug = augmentor(image=image, bounding_boxes=bbs)\n",
        "    #   disregard bounding boxes which have fallen out of image pane    \n",
        "        bbs_aug = bbs_aug.remove_out_of_image()\n",
        "    #   clip bounding boxes which are partially outside of image pane\n",
        "        bbs_aug = bbs_aug.clip_out_of_image()\n",
        "        \n",
        "    #   don't perform any actions with the image if there are no bounding boxes left in it    \n",
        "        if re.findall('Image...', str(bbs_aug)) == ['Image([]']:\n",
        "            pass\n",
        "        \n",
        "    #   otherwise continue\n",
        "        else:\n",
        "        #   write augmented image to a file\n",
        "            imageio.imwrite(aug_images_path+image_prefix+filename, image_aug)  \n",
        "        #   create a data frame with augmented values of image width and height\n",
        "            info_df = group_df.drop(['xmin', 'ymin', 'xmax', 'ymax'], axis=1)    \n",
        "            for index, _ in info_df.iterrows():\n",
        "                info_df.at[index, 'width'] = image_aug.shape[1]\n",
        "                info_df.at[index, 'height'] = image_aug.shape[0]\n",
        "        #   rename filenames by adding the predifined prefix\n",
        "            info_df['filename'] = info_df['filename'].apply(lambda x: image_prefix+x)\n",
        "        #   create a data frame with augmented bounding boxes coordinates using the function we created earlier\n",
        "            bbs_df = bbs_obj_to_df(bbs_aug)\n",
        "        #   concat all new augmented info into new data frame\n",
        "            aug_df = pd.concat([info_df, bbs_df], axis=1)\n",
        "        #   append rows to aug_bbs_xy data frame\n",
        "            aug_bbs_xy = pd.concat([aug_bbs_xy, aug_df])            \n",
        "    \n",
        "    # return dataframe with updated images and bounding boxes annotations \n",
        "    aug_bbs_xy = aug_bbs_xy.reset_index()\n",
        "    aug_bbs_xy = aug_bbs_xy.drop(['index'], axis=1)\n",
        "    return aug_bbs_xy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ab2pk5h5dCUW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if os.path.exists('/content/obj_det_plantas/models/object_detection/data/images/train/aug_images'):\n",
        "  shutil.rmtree('/content/obj_det_plantas/models/object_detection/data/images/train/aug_images')\n",
        "  \n",
        "os.mkdir('/content/obj_det_plantas/models/object_detection/data/images/train/aug_images') "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6iExE-F4dD3H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if os.path.exists('/content/obj_det_plantas/models/object_detection/data/images/test/aug_images'):\n",
        "  shutil.rmtree('/content/obj_det_plantas/models/object_detection/data/images/test/aug_images')\n",
        "\n",
        "os.mkdir('/content/obj_det_plantas/models/object_detection/data/images/test/aug_images') "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uji4U6PqdFWo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#augmented_images_train_df = image_aug(resized_train_images_df, '/content/obj_det_plantas/models/object_detection/data/images/train/', '/content/obj_det_plantas/models/object_detection/data/images/train/aug_images/', 'aug1_', aug)\n",
        "\n",
        "# initialize empty DataFrame\n",
        "augmented_images_train_df = pd.DataFrame(columns=['filename','width','height','class','xmin','ymin','xmax','ymax'])\n",
        "\n",
        "# apply augmentation function 5 times to the same set of images\n",
        "for i in range(10):\n",
        "    aug_df = image_aug(resized_train_images_df, '/content/obj_det_plantas/models/object_detection/data/images/train/', '/content/obj_det_plantas/models/object_detection/data/images/train/aug_images/', 'aug'+str(i)+'_', aug)\n",
        "    augmented_images_train_df = pd.concat([augmented_images_train_df, aug_df])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mCnpOgCtdG7s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#augmented_images_test_df = image_aug(resized_test_images_df, '/content/obj_det_plantas/models/object_detection/data/images/test/', '/content/obj_det_plantas/models/object_detection/data/images/test/aug_images/', 'aug1_', aug)\n",
        "\n",
        "# initialize empty DataFrame\n",
        "augmented_images_test_df = pd.DataFrame(columns=['filename','width','height','class','xmin','ymin','xmax','ymax'])\n",
        "\n",
        "# apply augmentation function 5 times to the same set of images\n",
        "for i in range(10):\n",
        "    aug_df = image_aug(resized_test_images_df, '/content/obj_det_plantas/models/object_detection/data/images/test/', '/content/obj_det_plantas/models/object_detection/data/images/test/aug_images/', 'aug'+str(i)+'_', aug)\n",
        "    augmented_images_test_df = pd.concat([augmented_images_test_df, aug_df])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wF48bKZPdIcN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_labels_train_df = pd.concat([resized_train_images_df, augmented_images_train_df])\n",
        "all_labels_train_df.to_csv('/content/obj_det_plantas/models/object_detection/data/annotations/train_labels.csv', index=False)\n",
        "\n",
        "all_labels_test_df = pd.concat([resized_test_images_df, augmented_images_test_df])\n",
        "all_labels_test_df.to_csv('/content/obj_det_plantas/models/object_detection/data/annotations/test_labels.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Ftz_tVKdJzg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for file in os.listdir('/content/obj_det_plantas/models/object_detection/data/images/train/aug_images/'):\n",
        "    shutil.copy('/content/obj_det_plantas/models/object_detection/data/images/train/aug_images/'+file, '/content/obj_det_plantas/models/object_detection/data/images/train/'+file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OLvmiL39dLDy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for file in os.listdir('/content/obj_det_plantas/models/object_detection/data/images/test/aug_images/'):\n",
        "    shutil.copy('/content/obj_det_plantas/models/object_detection/data/images/test/aug_images/'+file, '/content/obj_det_plantas/models/object_detection/data/images/test/'+file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O5pVpxzqk1vz",
        "colab_type": "text"
      },
      "source": [
        "###Generamos train.record y test.record a partir de los .csv"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qVVU8uoLdap8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd {repo_dir_path}/models/object_detection\n",
        "\n",
        "# Convert train folder annotation xml files to a single csv file,\n",
        "# generate the `label_map.pbtxt` file to `data/` directory as well.\n",
        "!python code/xml_to_csv.py -i data/images/train -o data/annotations/trainn_labels.csv -l data/annotations\n",
        "\n",
        "# Convert test folder annotation xml files to a single csv.\n",
        "#!python code/xml_to_csv.py -i data/images/test -o data/annotations/test_labels.csv\n",
        "\n",
        "# Generate `train.record`\n",
        "!python code/generate_tfrecord.py --csv_input=data/annotations/train_labels.csv --output_path=data/annotations/train.record --img_path=data/images/train --label_map data/annotations/label_map.pbtxt\n",
        "\n",
        "# Generate `test.record`\n",
        "!python code/generate_tfrecord.py --csv_input=data/annotations/test_labels.csv --output_path=data/annotations/test.record --img_path=data/images/test --label_map data/annotations/label_map.pbtxt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6_bZR1Kbk69Q",
        "colab_type": "text"
      },
      "source": [
        "###Listo. Bajar train.record, test.record y subirlos a Github."
      ]
    }
  ]
}